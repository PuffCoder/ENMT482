\documentclass[a4paper, 12pt]{article}
\usepackage{url}
\usepackage{pgf}
% This requires pdflatex -shell-escape
\usepackage{minted}

\setlength{\oddsidemargin}{0mm}
\setlength{\evensidemargin}{-14mm}
\setlength{\marginparwidth}{0cm}
\setlength{\marginparsep}{0cm}
\setlength{\topmargin}{2mm}
\setlength{\headheight}{0mm}
\setlength{\headsep}{0cm}
\setlength{\textheight}{240mm}
\setlength{\textwidth}{168mm}
\setlength{\topskip}{0mm}
\setlength{\footskip}{10mm}

% This is needed to handle unicode minus signs output by matplotlib pgf.
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{2212}{-}

\newcommand{\est}[1]{\expandafter\hat#1}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\var}[1]{\sigma_{#1}^2}
\newcommand{\std}[1]{\sigma_{#1}}
\newcommand{\reffig}[1]{\mbox{Figure~\ref{fig:#1}}}
\newcommand{\argmin}{\mathop{\rm arg\;min}}
\newcommand{\encp}[1]{\left(#1\right)}

\title{ENMT482 Assignment 1 Guide}
\author{M.P. Hayes}
\date{}

\begin{document}
\maketitle


\section{Part A}

This part of the assignment is about localising the position of a
robot in 1-D using a number of sensors.  The goal is to create sensor
models, a motion model, and to use a Bayes filter to improve the
estimate.  The better the model, the better the estimation.


\subsection{Sensor models}

In general, for each sensor, you want a model of the form:
%
\begin{equation}
  Z = h(x) + V(x).
\end{equation}


\begin{enumerate}
\item Download the data files and example scripts from Learn.

\item Plot the sensor data using the file \url{calibration.csv} (see
  Python script \url{plot-calibration.py}).

\item Choose the sensors you wish to fuse (ignore the hard one to
  start with).

\item Fit a parametric model to the data for each sensor using
  parametric identification given measured pairs of data $(x_n, z_n)$,
  see \reffig{fit}.  Let's say your model is:
  %
  \begin{equation}
    h(x) = a + b x + c x^2.
  \end{equation}
  %
  The goal is to find the parameters $a$, $b$, and $c$ that minimise
  the residuals:
  %
    \begin{equation}
    v_n = z_n - h(x_n).
    \end{equation}

    You can fit your model by eye using trial-and-error to find the
    best parameters that produces residuals with zero mean and the
    minimum variance.  Alternatively, you can use an optimiser.  For
    example, here's some Python code:
%
\begin{minted}{python}
from scipy.optimize import curve_fit

def model(x, a, b, c):

    return a + b * x + c * x * x


# Load data x, z

params, cov = curve_fit(model, x, z)

zfit = model(x, *params)

residuals = z - zfit
\end{minted}

  Note, that the \code{curve\_fit()} function passes an array for the
  argument \code{x} so you have to return an array of the same size.
  If you have a piecewise model, you can do something like:

\begin{minted}{python}
from scipy.optimize import curve_fit

def model(x, a, b, c):

    return a * (x < 1) + (b * x**2) * (x >= 1)

\end{minted}

\item The tricky aspect of model fitting is dealing with outliers.
  One approach is to iteratively fit a model and then remove the
  obvious outliers which have residuals many times the standard
  deviation.

  In Python, you can use NumPy fancy indexing to create a new array that
  ignores the outliers, for example:

  \begin{minted}{python}
    residuals = data - model
    mask = abs(residuals) < std(residuals) * 3
    pruned_data = data[mask]
  \end{minted}


  \begin{figure}[!h]
  \centering
  \input{figs/IRsensor-scatter.pgf}
  \caption{Non-linear sensor calibration data.}
  \label{fig:fit}
  \end{figure}

  \item The residuals of a good model have zero mean with minimal
    variance.  I suggest plotting the residuals, $v_n$, as a function of
    $x_n$ to see how good your model is.  For example, see
    \reffig{residuals}.

    \begin{figure}[!h]
  \centering
  \input{figs/IRsensor-error.pgf}
  \caption{Error between measured data and model for non-linear sensor
    calibration data.}
  \label{fig:residuals}
  \end{figure}

\item Determine how good each sensor is, i.e., what is its variance,
  see \reffig{histogram}.  The tricky aspect is that some sensors have
  a variance that varies with $x$.  If this is the case, you need to
  create a model for this, i.e., you need $\std{V(x)}$.  Note, if the
  variance changes slowly with $x$, a simple look-up table would
  suffice.

  \begin{figure}[!h]
  \centering
  \input{figs/IRsensor-error-histogram.pgf}
  \caption{Histogram of residuals (difference between measured data
    and model) for non-linear sensor calibration data in the range $0
    \le x \le 1$.}
  \label{fig:histogram}
  \end{figure}

\end{enumerate}


\subsection{Motion model}

Here you need a model of the form:
%
\begin{equation}
  X_n = g(X_{n-1}, u_{n-1}) + W_n,
\end{equation}
%
where $u_{n-1}$ is the commanded speed.

\begin{enumerate}
\item Plot the commanded speed and the estimated speed (using the
  distance data) in the training files, \url{training1.csv} and
  \url{training2.csv}, and ponder what is going on.

\item Determine a motion model, $g(x_{n-1}, u_{n-1})$.  A crude model
  is simply:
  %
  \begin{equation}
    g(x_{n-1}, u_{n-1}) = x_{n-1} + u_{n-1} \Delta t,
  \end{equation}
  %
  where $u_{n-1}$ is the commanded speed from the previous time-step.

  The residuals of a good model have zero mean with minimal variance.
  Again I suggest plotting the residuals, $w_n$, to see how good your
  fit is.  The process noise residuals are given by
  %
  \begin{equation}
    w_n = x_n - g(x_{n-1}, u_{n-1}).
  \end{equation}

\item Determine the process noise variance, $\var{W}$, for your motion model.

\end{enumerate}


\subsection{Sensor fusion}


Here you need a Bayes filter; an extended Kalman filter is easiest to
start with.  However, you will need to linearise your non-linear
sensors around the current best estimate of the robot's position.

\begin{enumerate}
\item Predict the robot's position using the previous estimated
  position and your motion model.

\item Determine the variance of the predicted robot's position.

\item For each sensor, invert its model $h(x)$.  So given a
  measurement $z$ you can find an estimate using $\est{x} =
  h^{-1}(z)$.  If the model has multiple solutions, pick the solution
  closest to the current estimate.

  If the model is not easily invertible you can use an optimisation
  algorithm to search for the estimate:
  %
  \begin{equation}
    \est{x} = \argmin_x \encp{h(x) - z}^2.
  \end{equation}
  %
  If there are multiple solutions, constrain the search around the
  current estimate.  Here's an example in Python using a brute-force
  search:

  \begin{minted}{python}
from scipy.optimize import brute

def h(x):
    return 0.3 / (0.1 + x)

def h_inverse(z, xmin, xmax):

    def f(x, z):
        return abs(h(x) - z)**2

    xest = brute(f, ((xmin, xmax), ), (z, ))[0]
    return xest

print(invert_h(z(5), 0, 10))
  \end{minted}

\item For each sensor, determine its noise variance $\var{V}(x)$ at
  the current best estimate for $x$.

\item For each sensor, determine the variance of the estimator
  $\var{\est{X}}(x)$,
  %
  \begin{equation}
    \var{\est{X}}(x) = \frac{1}{c^2(x)} \var{V}(x).
  \end{equation}
  %
  If the model is non-linear, $c(x)$ is the local slope at the current
  best estimate for $x$ (see the sensor fusion supplement in the lecture notes).

  \begin{figure}[!h]
  \centering
  \input{figs/IRsensor-linearised.pgf}
  \caption{Non-linear sensor model linearised around $x=5$.}
  \label{fig:linearised}
  \end{figure}

\item Combine the estimates from each sensor using a BLUE (see lecture
  notes).  To check that you have the correct weights, plot the
  weights for each sensor at each time-step.

\item Combine the prediction from the motion model with the estimates
  from the sensors using a BLUE.  This can be done at the same time as
  the previous step.

\item Determine the variance of the BLUE estimator (see lecture
  notes).

\item Rinse and repeat.
\end{enumerate}

Tips:
%
\begin{enumerate}
\item Test your filter with just the motion model.

\item Test your filter with the motion model and the best sensor and
  plot the BLUE weights.  Do not worry about range varying variance;
  just use worst-case result.  Single step each time-step and check
  the calculations.

\item Test your filter with the motion model and the two best sensors
  and plot the BLUE weights.
\end{enumerate}


\section{Part B}

This part of the assignment is about localising the position of a
robot in 2-D using fiducial markers (beacons) and a particle filter.
These markers are sensed by a camera on a Turtlebot2 robot to estimate
the local pose of the marker with respect to the robot.


The particle filter algorithm is written for you but you need to write
motion and sensor models.  If you are feeling clever, you might try
adapting the number of particles and/or not using knowledge of the
starting position.


\subsection{Motion model}

You can use either the velocity or odometry motion models.  The latter
has the advantage of decoupling the errors, see lecture notes.

To test your motion model, disable the sensor model (so that the
particle weights do not change) and see if the particles move by the
correct amount in the correct direction.  A useful Python script is
`test-motion-model.py`.

Once the particles are moving correctly, add some random behaviour to
the motion of each particle to mimic process noise.  The amount of
randomness depends on how good your motion model is.  However, it is
difficult to evaluate the process noise and I suggest that you tweak
this by trial and error, starting with a small amount of noise.


\subsection{Sensor model}


To correctly implement the sensor model you will need to understand:
%
\begin{enumerate}
\item The difference between the robot and global (map) reference frames.

\item How to calculate the range and bearing of the beacons with
  respect to the robot given the estimated pose of the beacons.

\item How to calculate the range and bearing of the beacons with
  respect to each particle.

\item How to use the \code{arctan2} function.

\item How to determine the smallest angle between two vectors.
\end{enumerate}
%
All these aspects are covered in the lecture notes.

Unfortunately, there is no calibration data for the fiducial marker
sensor.  I suggest modelling the sensor noise (in both range and
bearing) as Gaussian random noise and choosing the standard deviation
by trial and error.  A range standard deviation of 0.1 m and an angle
standard deviation of 0.1 radian will get you in the ballpark.  Note,
the standard deviation will vary with the observed pose of the marker
(it will be more accurate front-on than side-on) and the distance to
the marker.

\subsection{Particle filter}

The more particles you have, the better the estimate but the slower
the computation.

Here's what I suggest you do:

\begin{enumerate}
\item Test motion model without adding noise to particles and disable
  sensor model.  The particles should move in the correct direction.

\item Test motion model with added noise and disable sensor model.
  The particles should move in the correct direction but spread out.

\item Enable sensor model but with large standard deviations for the
  range and bearing errors.  The particles should get closer together
  whenever a beacon is visible.

\item Reduce standard deviations in sensor model to get better
  tracking.
\end{enumerate}


\section{Miscellaneous}

\subsection{Calculating angle}

In mathematics we determine the angle of a right-angled triangle from
the opposite, $y$, and adjacent, $x$, distances using
%
\begin{equation}
  \theta = \tan^{1} \frac{y}{x}.
\end{equation}
%
Numerically you need to use the arctan2 function (Python) or atan2
function (C), \code{theta = arctan2(y, x)}.  This determines the
correct quadrant and avoids singularies when $x$ is zero.


\subsection{Calculating angle between two angles}


When calculating angle between two vectors we usually want the
smallest difference.  For example, let $\theta_1 = 315$\,degrees and
$\theta_2 = 45$\,degrees.  $\theta_1 - \theta_2 = 270$\,degrees.
However, this does not take the angle wrapping into account since the
smallest angle between the vectors is 90\,degrees.


\end{document}
